{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates\n",
    "month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "day = ['01','02','03','04','05','06','07','08','09','10'] + list(range(32)[11:])\n",
    "day = [str(d) for d in day]\n",
    "letter = ['a','b','c','d','e','f','g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data from 1990-01...\n",
      "Scraping data from 1990-02...\n",
      "Scraping data from 1990-03...\n",
      "Scraping data from 1990-04...\n",
      "Scraping data from 1990-05...\n",
      "Scraping data from 1990-06...\n",
      "Scraping data from 1990-07...\n",
      "Scraping data from 1990-08...\n",
      "Scraping data from 1990-09...\n",
      "Scraping data from 1990-10...\n",
      "Scraping data from 1990-11...\n",
      "Scraping data from 1990-12...\n",
      "Scraping data from 1991-01...\n",
      "Scraping data from 1991-02...\n",
      "Scraping data from 1991-03...\n",
      "Scraping data from 1991-04...\n",
      "Scraping data from 1991-05...\n",
      "Scraping data from 1991-06...\n",
      "Scraping data from 1991-07...\n",
      "Scraping data from 1991-08...\n",
      "Scraping data from 1991-09...\n",
      "Scraping data from 1991-10...\n",
      "Scraping data from 1991-11...\n",
      "Scraping data from 1991-12...\n",
      "Scraping data from 1992-01...\n",
      "Scraping data from 1992-02...\n",
      "Scraping data from 1992-03...\n",
      "Scraping data from 1992-04...\n",
      "Scraping data from 1992-05...\n",
      "Scraping data from 1992-06...\n",
      "Scraping data from 1992-07...\n",
      "Scraping data from 1992-08...\n",
      "Scraping data from 1992-09...\n",
      "Scraping data from 1992-10...\n",
      "Scraping data from 1992-11...\n",
      "Scraping data from 1992-12...\n",
      "Scraping data from 1993-01...\n",
      "Scraping data from 1993-02...\n",
      "Scraping data from 1993-03...\n",
      "Scraping data from 1993-04...\n",
      "Scraping data from 1993-05...\n",
      "Scraping data from 1993-06...\n",
      "Scraping data from 1993-07...\n",
      "Scraping data from 1993-08...\n",
      "Scraping data from 1993-09...\n",
      "Scraping data from 1993-10...\n",
      "Scraping data from 1993-11...\n",
      "Scraping data from 1993-12...\n",
      "Scraping data from 1994-01...\n",
      "Scraping data from 1994-02...\n",
      "Scraping data from 1994-03...\n",
      "Scraping data from 1994-04...\n",
      "Scraping data from 1994-05...\n",
      "Scraping data from 1994-06...\n",
      "Scraping data from 1994-07...\n",
      "Scraping data from 1994-08...\n",
      "Scraping data from 1994-09...\n",
      "Scraping data from 1994-10...\n",
      "Scraping data from 1994-11...\n",
      "Scraping data from 1994-12...\n",
      "Scraping data from 1995-01...\n",
      "Scraping data from 1995-02...\n",
      "Scraping data from 1995-03...\n",
      "Scraping data from 1995-04...\n",
      "Scraping data from 1995-05...\n",
      "Scraping data from 1995-06...\n",
      "Scraping data from 1995-07...\n",
      "Scraping data from 1995-08...\n",
      "Scraping data from 1995-09...\n",
      "Scraping data from 1995-10...\n",
      "Scraping data from 1995-11...\n",
      "Scraping data from 1995-12...\n",
      "Scraping data from 1996-01...\n",
      "Scraping data from 1996-02...\n",
      "Scraping data from 1996-03...\n",
      "Scraping data from 1996-04...\n",
      "Scraping data from 1996-05...\n",
      "Scraping data from 1996-06...\n",
      "Scraping data from 1996-07...\n",
      "Scraping data from 1996-08...\n",
      "Scraping data from 1996-09...\n",
      "Scraping data from 1996-10...\n",
      "Scraping data from 1996-11...\n",
      "Scraping data from 1996-12...\n",
      "Scraping data from 1997-01...\n",
      "Scraping data from 1997-02...\n",
      "Scraping data from 1997-03...\n",
      "Scraping data from 1997-04...\n",
      "Scraping data from 1997-05...\n",
      "Scraping data from 1997-06...\n",
      "Scraping data from 1997-07...\n",
      "Scraping data from 1997-08...\n",
      "Scraping data from 1997-09...\n",
      "Scraping data from 1997-10...\n",
      "Scraping data from 1997-11...\n",
      "Scraping data from 1997-12...\n",
      "Scraping data from 1998-01...\n",
      "Scraping data from 1998-02...\n",
      "Scraping data from 1998-03...\n",
      "Scraping data from 1998-04...\n",
      "Scraping data from 1998-05...\n",
      "Scraping data from 1998-06...\n",
      "Scraping data from 1998-07...\n",
      "Scraping data from 1998-08...\n",
      "Scraping data from 1998-09...\n",
      "Scraping data from 1998-10...\n",
      "Scraping data from 1998-11...\n",
      "Scraping data from 1998-12...\n",
      "Scraping data from 1999-01...\n",
      "Scraping data from 1999-02...\n",
      "Scraping data from 1999-03...\n",
      "Scraping data from 1999-04...\n",
      "Scraping data from 1999-05...\n",
      "Scraping data from 1999-06...\n",
      "Scraping data from 1999-07...\n",
      "Scraping data from 1999-08...\n",
      "Scraping data from 1999-09...\n",
      "Scraping data from 1999-10...\n",
      "Scraping data from 1999-11...\n",
      "Scraping data from 1999-12...\n"
     ]
    }
   ],
   "source": [
    "# Scrape data from 1990-1999:\n",
    "\n",
    "year = ['90','91','92','93','94','95','96','97','98','99']\n",
    "number = 0\n",
    "heading = \"\"\n",
    "\n",
    "for y in year:\n",
    "    for m in month:\n",
    "        print(\"Scraping data from 19\" + y + \"-\" + m + \"...\")\n",
    "        for d in day:\n",
    "            newday = True\n",
    "            newurl = \"http://www.theyworkforyou.com/pwdata/scrapedxml/debates/debates19\" + y + '-' + m + '-' + d + \"a.xml\"\n",
    "            try:\n",
    "                document = urllib.request.urlopen(newurl).read()\n",
    "            except:\n",
    "                continue\n",
    "            root = ET.fromstring(document)\n",
    "            for child in root:\n",
    "                if(child.tag == 'major-heading'):\n",
    "                    if (number != 0) and (not newday):\n",
    "                        if(len(speech) < 400):\n",
    "                            number -= 1\n",
    "                        else:\n",
    "                            outputpath = \"/Users/xiaoyusun/Downloads/TTIC 31220/Project/data2/C\" + str(number) + \".txt\"\n",
    "                            with open(outputpath, 'w') as file:\n",
    "                                file.write(heading + '\\n\\n')\n",
    "                                file.write('19' + y + '-' + m + '-' + d + '\\n\\n')\n",
    "                                file.write(speech)\n",
    "                    number += 1\n",
    "                    heading = str(child.text)\n",
    "                    speech = \"\"\n",
    "                    newday = False\n",
    "                if(child.tag == 'speech'):\n",
    "                    speech = speech + \"\".join(child.itertext()) + \"\\n\"\n",
    "            if(number != 0):\n",
    "                if(len(speech) < 400):\n",
    "                    number -= 1\n",
    "                else:\n",
    "                    outputpath = \"/Users/xiaoyusun/Downloads/TTIC 31220/Project/data2/C\" + str(number) + \".txt\"\n",
    "                    with open(outputpath, 'w') as file:\n",
    "                        file.write(heading + '\\n\\n')\n",
    "                        file.write('19' + y + '-' + m + '-' + d + '\\n\\n')\n",
    "                        file.write(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data from 2009-01...\n",
      "Scraping data from 2009-02...\n",
      "Scraping data from 2009-03...\n",
      "Scraping data from 2009-04...\n",
      "Scraping data from 2009-05...\n",
      "Scraping data from 2009-06...\n",
      "Scraping data from 2009-07...\n",
      "Scraping data from 2009-08...\n",
      "Scraping data from 2009-09...\n",
      "Scraping data from 2009-10...\n",
      "Scraping data from 2009-11...\n",
      "Scraping data from 2009-12...\n",
      "Scraping data from 2010-01...\n",
      "Scraping data from 2010-02...\n",
      "Scraping data from 2010-03...\n",
      "Scraping data from 2010-04...\n",
      "Scraping data from 2010-05...\n",
      "Scraping data from 2010-06...\n",
      "Scraping data from 2010-07...\n",
      "Scraping data from 2010-08...\n",
      "Scraping data from 2010-09...\n",
      "Scraping data from 2010-10...\n",
      "Scraping data from 2010-11...\n",
      "Scraping data from 2010-12...\n",
      "Scraping data from 2011-01...\n",
      "Scraping data from 2011-02...\n",
      "Scraping data from 2011-03...\n",
      "Scraping data from 2011-04...\n",
      "Scraping data from 2011-05...\n",
      "Scraping data from 2011-06...\n",
      "Scraping data from 2011-07...\n",
      "Scraping data from 2011-08...\n",
      "Scraping data from 2011-09...\n",
      "Scraping data from 2011-10...\n",
      "Scraping data from 2011-11...\n",
      "Scraping data from 2011-12...\n",
      "Scraping data from 2012-01...\n",
      "Scraping data from 2012-02...\n",
      "Scraping data from 2012-03...\n",
      "Scraping data from 2012-04...\n",
      "Scraping data from 2012-05...\n",
      "Scraping data from 2012-06...\n",
      "Scraping data from 2012-07...\n",
      "Scraping data from 2012-08...\n",
      "Scraping data from 2012-09...\n",
      "Scraping data from 2012-10...\n",
      "Scraping data from 2012-11...\n",
      "Scraping data from 2012-12...\n",
      "Scraping data from 2013-01...\n",
      "Scraping data from 2013-02...\n",
      "Scraping data from 2013-03...\n",
      "Scraping data from 2013-04...\n",
      "Scraping data from 2013-05...\n",
      "Scraping data from 2013-06...\n",
      "Scraping data from 2013-07...\n",
      "Scraping data from 2013-08...\n",
      "Scraping data from 2013-09...\n",
      "Scraping data from 2013-10...\n",
      "Scraping data from 2013-11...\n",
      "Scraping data from 2013-12...\n",
      "Scraping data from 2014-01...\n",
      "Scraping data from 2014-02...\n",
      "Scraping data from 2014-03...\n",
      "Scraping data from 2014-04...\n",
      "Scraping data from 2014-05...\n",
      "Scraping data from 2014-06...\n",
      "Scraping data from 2014-07...\n",
      "Scraping data from 2014-08...\n",
      "Scraping data from 2014-09...\n",
      "Scraping data from 2014-10...\n",
      "Scraping data from 2014-11...\n",
      "Scraping data from 2014-12...\n",
      "Scraping data from 2015-01...\n",
      "Scraping data from 2015-02...\n",
      "Scraping data from 2015-03...\n",
      "Scraping data from 2015-04...\n",
      "Scraping data from 2015-05...\n",
      "Scraping data from 2015-06...\n",
      "Scraping data from 2015-07...\n",
      "Scraping data from 2015-08...\n",
      "Scraping data from 2015-09...\n",
      "Scraping data from 2015-10...\n",
      "Scraping data from 2015-11...\n",
      "Scraping data from 2015-12...\n",
      "Scraping data from 2016-01...\n",
      "Scraping data from 2016-02...\n",
      "Scraping data from 2016-03...\n",
      "Scraping data from 2016-04...\n",
      "Scraping data from 2016-05...\n",
      "Scraping data from 2016-06...\n",
      "Scraping data from 2016-07...\n",
      "Scraping data from 2016-08...\n",
      "Scraping data from 2016-09...\n",
      "Scraping data from 2016-10...\n",
      "Scraping data from 2016-11...\n",
      "Scraping data from 2016-12...\n",
      "Scraping data from 2017-01...\n",
      "Scraping data from 2017-02...\n",
      "Scraping data from 2017-03...\n",
      "Scraping data from 2017-04...\n",
      "Scraping data from 2017-05...\n",
      "Scraping data from 2017-06...\n",
      "Scraping data from 2017-07...\n",
      "Scraping data from 2017-08...\n",
      "Scraping data from 2017-09...\n",
      "Scraping data from 2017-10...\n",
      "Scraping data from 2017-11...\n",
      "Scraping data from 2017-12...\n",
      "Scraping data from 2018-01...\n",
      "Scraping data from 2018-02...\n",
      "Scraping data from 2018-03...\n",
      "Scraping data from 2018-04...\n",
      "Scraping data from 2018-05...\n",
      "Scraping data from 2018-06...\n",
      "Scraping data from 2018-07...\n",
      "Scraping data from 2018-08...\n",
      "Scraping data from 2018-09...\n",
      "Scraping data from 2018-10...\n",
      "Scraping data from 2018-11...\n",
      "Scraping data from 2018-12...\n"
     ]
    }
   ],
   "source": [
    "# Scrape data from 2009--2018\n",
    "\n",
    "year = ['09','10','11','12','13','14','15','16','17','18']\n",
    "number = 0\n",
    "heading = \"\"\n",
    "\n",
    "for y in year:\n",
    "    for m in month:\n",
    "        print(\"Scraping data from 20\" + y + \"-\" + m + \"...\")\n",
    "        for d in day:\n",
    "            for l in letter:\n",
    "                newxml = True\n",
    "                newurl = \"http://www.theyworkforyou.com/pwdata/scrapedxml/debates/debates20\" + y + '-' + m + '-' + d + l + \".xml\"\n",
    "                try:\n",
    "                    document = urllib.request.urlopen(newurl).read()\n",
    "                except:\n",
    "                    break\n",
    "                root = ET.fromstring(document)\n",
    "                for child in root:\n",
    "                    if(child.tag == 'major-heading'):\n",
    "                        if (number != 0) and (not newxml):\n",
    "                            if(len(speech) < 400):\n",
    "                                number -= 1\n",
    "                            else:\n",
    "                                outputpath = \"/Users/xiaoyusun/Downloads/TTIC 31220/Project/data2/B\" + str(number) + \".txt\"\n",
    "                                with open(outputpath, 'w') as file:\n",
    "                                    file.write(heading + '\\n\\n')\n",
    "                                    file.write('20' + y + '-' + m + '-' + d + ' ' + l + '\\n\\n')\n",
    "                                    file.write(speech)\n",
    "                        number += 1\n",
    "                        heading = str(child.text)\n",
    "                        speech = \"\"\n",
    "                        newxml = False\n",
    "                    if(child.tag == 'speech'):\n",
    "                        speech = speech + \"\".join(child.itertext()) + \"\\n\"\n",
    "                if(number != 0):\n",
    "                    if(len(speech) < 400):\n",
    "                        number -= 1\n",
    "                    else:\n",
    "                        outputpath = \"/Users/xiaoyusun/Downloads/TTIC 31220/Project/data2/B\" + str(number) + \".txt\"\n",
    "                        with open(outputpath, 'w') as file:\n",
    "                            file.write(heading + '\\n\\n')\n",
    "                            file.write('20' + y + '-' + m + '-' + d + ' ' + l + '\\n\\n')\n",
    "                            file.write(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
